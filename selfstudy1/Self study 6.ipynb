{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this self study you will explore Pyro a bit further, bu as opposed to the last self study session where focus was on modeling we will here take a slightly closer lool at (variational) inference. in Pyro \n",
    "\n",
    "Before starting on today's self studies, you should finish the self studies from last tme if you have not already done so. Also, if needed, consider revisiting the Pyro documentation listed under reading material for the last two lectures:\n",
    "* http://pyro.ai/examples/intro_long.html\n",
    "* http://pyro.ai/examples/bayesian_regression.html\n",
    "* http://pyro.ai/examples/svi_part_i.html\n",
    "\n",
    "Afterwards, continue with the notebook below, where we consider (Bayesian) linear regression using Pyro based on the same setup as in the lecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import torch\n",
    "import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro.distributions as dist\n",
    "import torch.distributions.constraints as constraints\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam, SGD\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data\n",
    "This data generation is similar to what was done during the lecture; we have one predictor variable 'x' and one response variable 'y', but here collected in a  dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(N=10, true_w0= 1., true_w1=.5):\n",
    "    gamma = 4.  # The *precision* in the observation noise\n",
    "    st_dev = 1. / np.sqrt(gamma)  # And corresponding standard deviation\n",
    "    np.random.seed(123)\n",
    "    x = 5 * np.random.rand(N)  # The x-points are sampled uniformly on [0, 5]\n",
    "    y = np.random.normal(loc=true_w0 + true_w1 * x, scale=st_dev)  # And the response is sampled from the Normal\n",
    "    return {\"x\": torch.tensor(x, dtype=torch.float), \"y\": torch.tensor(y, dtype=torch.float)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for visualizing the data as well as the true and learned functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_plotter(data, true_w0=None, true_w1=None,\n",
    "                 approx_w0=None, approx_w1=None, legend=True):\n",
    "    \"\"\"\n",
    "    Use to plot data. If y is not none it contains responses, and (x,y) will be scatter-plotted\n",
    "    If neither true_w0 nor true_w1 is None, we will plot the line true_w0 + x * true_w1 in red.\n",
    "    If neither approx_w0 nor approx_w1 is None, we plot the line approx_w0 + x * approx_w1 in green.\n",
    "    \"\"\"\n",
    "    if data is not None:\n",
    "        plt.plot(data[\"x\"].numpy(), data[\"y\"].numpy(), \"bo\", label=\"data\", )\n",
    "\n",
    "    # Plot true line if given\n",
    "    if true_w0 is not None and true_w1 is not None:\n",
    "        plt.plot(data[\"x\"].numpy(), true_w0 + true_w1 * data[\"x\"].numpy(), \"r-\", label=\"true\")\n",
    "\n",
    "    # Plot approximation if given\n",
    "    if approx_w0 is not None and approx_w1 is not None:\n",
    "        # set z index to make sure the line is on top of the data\n",
    "        plt.plot(data[\"x\"].numpy(), approx_w0+ approx_w1* data[\"x\"].numpy(), \"g-\", alpha=.2, label=\"approx\", zorder=10)\n",
    "    \n",
    "    if legend:\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a data set with 50 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_w0= 1.\n",
    "true_w1=.5\n",
    "data = generate_data(N=50, true_w0=true_w0, true_w1=true_w1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the data together with the regression line around which the data has been generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAfkklEQVR4nO3de5SV1X038O8XGB1QKAlMKTo4w2s0RokgDGgWYllWEry8GKtW24nBFVtqNK22qa2Kr7cs2lhdxhCXUbwkupimLcZbiKZxKd5qxQwGdARdhWaEobgYRkEugsD83j/2OcycM+fMuT335/tZ6yxmnvPMOXsOM9+zZz+/vTfNDCIiEn9Dwm6AiIh4Q4EuIpIQCnQRkYRQoIuIJIQCXUQkIYaF9cRjx4615ubmsJ5eRCSWVq1atc3MGgrdF1qgNzc3o729PaynFxGJJZIfFLtPQy4iIgmhQBcRSQgFuohIQoQ2hl7I/v370dXVhb1794bdFF/V19ejsbERdXV1YTdFRBKk7EAnORRAO4DNZnZe3n2HA3gMwDQAPQAuMbPOShvT1dWFkSNHorm5GSQr/fJYMDP09PSgq6sLEydODLs5IpIglQy5XANgXZH7rgDwsZl9AcAPANxRTWP27t2LMWPGJDbMAYAkxowZk/i/QkRkoLY2oLkZGDLE/dvW5u3jlxXoJBsBnAvgoSKnnA/g0czHjwP4I1aZykkO86w0fI8ikqutDViwAPjgA8DM/btggbehXm4P/R4Afw+gt8j9RwPYBABmdgDADgBj8k8iuYBkO8n27u7uylsrIhJTCxcCe/bkHtuzxx33SslAJ3kegK1mtqrWJzOzJWbWYmYtDQ0FJzpFzq233oq77rqr6P1PPfUU1q5dG2CLRCSONm6s7Hg1yumhzwQwj2QngH8FcCbJpXnnbAYwAQBIDgPwe3AXR33l93hUORToIlKOY46p7Hg1Sga6md1gZo1m1gzgUgAvmtk38k57BsD8zMcXZc7xdSskP8ejFi1ahOOPPx6nn3463n//fQDAgw8+iOnTp2Py5Mm48MILsWfPHrz++ut45plncN1112HKlCnYsGFDwfNERBYtAkaMyD02YoQ77hkzK/sGYDaA5ZmPbwcwL/NxPYBlANYDeBPA/yn1WNOmTbN8a9euHXCsmKYmMxflubemprIfoqD29nabNGmS7d6923bs2GHHHnus3XnnnbZt27ZD5yxcuNAWL15sZmbz58+3ZcuWHbqv2Hn5KvleRSQZli51GUW6f5curfwxALRbkVytaGKRmb0E4KXMxzf3O74XwMW1vbVUxq/xqFdffRUXXHABRmTeSufNmwcA6OjowE033YTt27dj165d+NrXvlbw68s9T0TSp7XV3fwS26n/QYxH9Xf55Zfj3nvvxTvvvINbbrmlaB15ueeJiHgttoHu13jUGWecgaeeegqffvopdu7ciV/84hcAgJ07d2L8+PHYv38/2voN1I8cORI7d+489Hmx80RE/BbbQG9tBZYsAZqaANL9u2RJ7X/OTJ06FZdccgkmT56Ms88+G9OnTwcAfO9738Opp56KmTNn4oQTTjh0/qWXXoo777wTp5xyCjZs2FD0PBERv9H8LUYpqqWlxfI3uFi3bh2+9KUvhdKeoKXpexUR75BcZWYthe6LbQ9dRERyKdBFRBJCgS4ikhAKdBGRhFCgi4gkhAJdRCQhFOj9bN++Hffdd1/YzRARqYoCvZ9igX7gwIEQWiMiUhkFej/XX389NmzYgClTpmD69OmYNWsW5s2bhxNPPBGdnZ2YNGnSoXPvuusu3HrrrQCADRs2YO7cuZg2bRpmzZqF9957L6TvQKQ2UdhjQKpX0WqLgbr2WmD1am8fc8oU4J57it79/e9/Hx0dHVi9ejVeeuklnHvuuejo6MDEiRPR2dlZ9OsWLFiA+++/H8cddxxWrlyJq666Ci+++KK3bRfxWXaPgewS/tk9BgB/VwgU70Q30CNgxowZmDhx4qDn7Nq1C6+//jouvrhv9eB9+/b53TQRzw2256UCPR6iG+iD9KSDcsQRRxz6eNiwYejt7dsjO7ssbm9vL0aPHo3VXv81IRKwIPa8FH9pDL2f/KVw+xs3bhy2bt2Knp4e7Nu3D8uXLwcAjBo1ChMnTsSyZcsAuB2g1qxZE1ibJXnCGscOeo8B8Z4CvZ8xY8Zg5syZmDRpEq677rqc++rq6nDzzTdjxowZmDNnTs7SuG1tbXj44YcxefJknHTSSXj66aeDbrokhJ975ZYSyJ6X4istnxuSNH2vUr7mZhfi+ZqagEGuy3umrc2NmW/c6HrmixZp/DxqBls+N7pj6CIpFPY4tt97Xoq/NOQiEiEax5ZaRC7QwxoCClIavkepjsaxpRYlA51kPck3Sa4h+S7J2wqccznJbpKrM7c/r6Yx9fX16OnpSXTgmRl6enpQX18fdlMkgvzaK1fSoZwx9H0AzjSzXSTrALxG8jkzeyPvvH8zs+/U0pjGxkZ0dXWhu7u7loeJvPr6ejQ2NobdDIkojWNLtUoGurnu8q7Mp3WZmy9d6Lq6upIzM0VE4iao6qGyxtBJDiW5GsBWAM+b2coCp11I8m2Sj5OcUORxFpBsJ9me9F64iAgQ7NyCsgLdzA6a2RQAjQBmkJyUd8ovADSb2ckAngfwaJHHWWJmLWbW0tDQUEOzRUTiof8aOUQvzsVyDN3zCRYu9P65KqpyMbPtAFYAmJt3vMfMsitSPQRgmietExGJuY0bgRHYDQPRi6FYjv+Li7HMl7kF5VS5NJAcnfl4OIA5AN7LO2d8v0/nAVjnYRtFROJpyxb0GrEbRx46tAKzsRTf8GVuQTk99PEAVpB8G8Bv4MbQl5O8neS8zDl/nSlpXAPgrwFc7n1TRSQI2uTCAx0dru70qKNyDg/HHpyJFRg24nBf5hZEai0XEQlX/iYXgJvYpFr4Mj3/PPDVrw443PbYQSz8f0M8qXIZbC0XBbqIHFJscbChQ4FHH1WoF/XQQ8Bf/EXusaOOAjZv9vypBgv0yE39F5HwFLtQd/BgcMv4xsr117uhlf5hfs45rj7RhzAvRYEuIocMdqEuux2dwIU4CdxxR9+xv/s7F+S//GVozVKgi8ghhRYH6y/129Flg7y/Bx5wQX7nneG0qR+thy4ih2THyOfPd8Ms+VK5jG9vr7uIkO/ee4Grrw6+PYNQoItIjmyoF6p2SdUyvrt3A0ceOfD4r38NzJkTfHvKoCEXERkgzsv41lxHv2mT+6bzw/y999zQSkTDHFCgiyRetQHX2ur2Me3tdf/GJcyrXghr5UoX5PnjSj097sG++EVf2uwlBbpIghUKuG99Cxg7Nv4zQQu9UfVfCCurZHXOv/yLC/LTTss9/tln7kX7/Oc9brl/NLFIJMGKTRTqL44zQYvNaM0P8yzS/aWR48YbgX/6p4EnR3zHNE0sEkmpcsoM41hfXqwnXqgYBcgbRZk71yV8fpibRT7MS1GgiyRYuWWGcasvH2xGa9FNto84wgX5f/xH352NjYkI8iwFukiClZoolBW3+vJi7c1W4/Svztm9h2j9BnO79Bdf7EJ806ZgGhwQBbpIguWXH44ZA9TV5Z4Tx/ryQm9U2e+jtRXo/J2h14jOD/Jmdf7jP7og//d/D66xAVKgiyRc//LDbduAn/wknvXl/RWtk79gjzswJC/annzSBfkNN4TT4ICoykVE4m/jRpfq+X77W2DKlMCb4ydVuYhIMr38cl8Xvb/OTtcjT1iYl6JAF5H4ueUWF+SzZ+ce37XLBXmh3noKaHEuEYmP008H/vM/Bx7v7R24rG0KKdBFJPqKhXVC6se9oiEXERmg5hULvVJoQwkgUZOBvKQeuojkyF8nJbtiIRBgeaN65FUp2UMnWU/yTZJrSL5L8rYC5xxO8t9Irie5kmSzL60VEd9VtWKhVwr1yJua1CMvUzlDLvsAnGlmkwFMATCXZN46k7gCwMdm9gUAPwBwB0Qkloqtk+Lbei/79hUO8r/8SxfinZ0+PXH1IjMkladkoJuzK/NpXeaW/1Z5PoBHMx8/DuCPSF1yFomjYuukeL7eS1eXC/H6+tzjjz3mgvz++z1+Qm/UtImGz8q6KEpyKMnVALYCeN7MVuadcjSATQBgZgcA7AAwpsDjLCDZTrK9u7u7poaLiD8GWyfFE6+84oJ8woTc46tWuYS87DKPnsgfoQ5JlVBWoJvZQTObAqARwAySk6p5MjNbYmYtZtbS0NBQzUOIiM9820/0hz90D/iHf5h7fNs2F+RTp9b4BMEIfEiqAhVVuZjZdpIrAMwF0NHvrs0AJgDoIjkMwO8B6PGslSISqNZWDyta/viP3eJY+fbvB4bFr9DumGMK7wIVhSWIy6lyaSA5OvPxcABzALyXd9ozAOZnPr4IwIsW1qpfIhINhx3meuT5YZ6tWIlhmAMBDEnVoJwhl/EAVpB8G8Bv4MbQl5O8neS8zDkPAxhDcj2AvwVwvT/NlaSLavWAVCBbsbJ/f+7xhJQe+jYk5QEtnyuRUWzj36j8skgJmgwUCC2fK6Eqt9cd5eoBGUShGvK6usT0yONEgS6+qqRmN8rVA5LnwIHCQX7BBe4/+rPPwmlXyinQEyoqY9GV9LoDm9Ai1du2zYV4/sak99zjgvyJJ0JpljgK9ASK0ky2SnrdUa4eSL3XXnNBnj9/5OWX3Q/ZNdeE0y7JoUBPoCiNRVfS645y9UBq3XST+8+YNSv3+KZNLsjPOCOcdklB8SwElUFFaSx60aLClSvFet2eTmiR6o0c6bZzy7dnDzB8ePDtkbKoh55AURqLVq87ZrIXOvPDPFuxojCPNAV6AkVtLLq11a2A2tvr/lWYR5B2BkoEBXoCqVcsZVOQJ4rG0BNKY9EyKM3qTCT10CVyolJDnzi9veqRJ5wCXSIlSjX0ibFliwvxoUNzj9fXpzLIk9xhUKBLpESphj72nnvOBflRR+Ue/6u/ciH+6afhtCtESe8wKNAlUryqoU9yL6ykq65yQX7OObnHf/Url2KLF4fTrghIeodBF0UlUrzYDSZ/Gd5sLwxI+IXiYcOAgwcHHv/wQ2DcuODbE0FRmnTnB/XQJVK8qKFPei9sgOyFzvwwP3jQ9cgV5odEadKdHxToUlKQwxde1NAnvRd2SKmKlSH69c4XtUl3XtOQiwwqjOGLWmvoo7yJrydUQ1617M/VwoXuDf6YY1yYJ2UoTlvQyaCamwuHY1OTm8YfRYndyk5BLtAWdFKDOA5fJGrpAzNNBpKyachFBhXX4YvYL32wfTvwuc8Vvk8hLkWohy6DSvpFpMh54QXXG88P869/XT1yKalkoJOcQHIFybUk3yU5YK8pkrNJ7iC5OnO72Z/mStASNXwRZQsWuBf4rLNyDt/w+QcwhIbm3z6ZrslRUpVyhlwOAPiumb1FciSAVSSfN7O1eee9ambned9ECVvshy+i7LDDgP37Bxxe/v0OXHL7Sdjzkfs8NZOjpCYle+hmtsXM3sp8vBPAOgBH+90wkUTLXujMD/O9ewEzfOfHJ6VrcpR4oqIxdJLNAE4BsLLA3V8huYbkcyRP8qJxIolTqmLl8MMBxLO6SMJXdqCTPBLAzwFca2af5N39FoAmM5sM4EcAniryGAtItpNs7+7urrLJIjFUYelh0qeoiz/KCnSSdXBh3mZmT+Tfb2afmNmuzMfPAqgjObbAeUvMrMXMWhoaGmpsukgMVFlDruoiqUY5VS4E8DCAdWZ2d5Fz/iBzHkjOyDxuj5cNFYmVGicDqbpIqlFOlctMAJcBeIfk6syxGwEcAwBmdj+AiwB8m+QBAJ8CuNTCWlNAJCx79wLDhxe+r4pfB1UXSaVKBrqZvQagyCISh865F8C9XjVKJFbeeQc4+eSBx0ePBj7+OPDmSHpppmjKpXpnn1rdfbcbD8kP8xtvdD1yhbkETIGeYknfX7FWRd/svvxlF+Tf/W7uF7z2mnshdeVSQqLlc1MsjkvjBqXQErxWbORxxw5g1KhgGiapN9jyuVptMcU0eaW4/tvYFQ1yXfeXiNGQS4pp8kpxGze6IC8Y5lr1UCJKgZ5imrxSBIleGxjkhKG5SUEu0aVATzFNXslTZDIQM311vdlJ1CnQU6611V0A7e11/6YuzA8eLBrkbUtdj1xvdhIXuigq6dTVBUyYUPi+zPh4KxTgEi/qoceEJgB55LnnXG88P8yvumrAxU695hI36qHHQH5NtHavqcJllwFLlw48/txzwNy5Aw7rNZc4Ug89BvrXRGfVuntNanqf2fHx/DDfutX1xguEOeDPax5nqfl5iTkFusf8+MH3egJQKqb8F1u+trfXfdMl1uPXpKs+qfh5SQgFuof8+sH3egJQWL3PQHp5pdYhL3RfAZp01Ud/rcSHAt1Dfv3gez0BKIzep++9vBo3lMinSVd99NdKfCjQPeTXD77XE4DC6H361svzOMizNOmqj/5aiQ8Fuof8/MH3cgJQGL1PT9/sskMnPgR5f0FNuor6BUf9tRIfCnQP1fqDH9Qvdhi9T0/e7D7+2DV4SIEf25gumBWHC476ayVGzCyU27Rp0yyJli41a2oyI92/S5eW/3UjRmRTyd1GjCj/66Oupu/vlVdyvzB7O/dc39vtt6amwt9aU1PYLZOoAtBuRXJVG1xERBo2m2hrc2PmGze6nvmiRSV6eddcAyxePPD4o48C3/ymb+0M0pAhhf+wIN1Qj0i+wTa40JBLRKShkqDsMelx41yi5Yf5+vUu/coM86iPTQO64CjeUqBHhH6x0Xehc+vW3OOffeaC/Nhjy36oOIxNA7rgKN5SoEdEqn+xS1Ws1NVV/JBxmQyjC47ipZKBTnICyRUk15J8l+Q1Bc4hycUk15N8m+RUf5qbXKn8xfax9DBOQ1ipX5NePFNOD/0AgO+a2YkATgNwNckT8845G8BxmdsCAD/2tJUpkZpf7ABqyJMyhBWH6wASHSUD3cy2mNlbmY93AlgH4Oi8084H8FimquYNAKNJjve8tRJvAQR5VhKGsOJyHUCio6IxdJLNAE4BsDLvrqMBbOr3eRcGhj5ILiDZTrK9u7u7wqZKLO3dG2iQZyVhCCsu1wEkOsoOdJJHAvg5gGvN7JNqnszMlphZi5m1NJRYvlRi7v33XZIOH557fPbswGZ1xn0IK07XASQaygp0knVwYd5mZk8UOGUzgP57ejVmjkna/OQnLshPOCH3+H33uRBfsWLQL9eYcZ+kXAeQ4JRT5UIADwNYZ2Z3FzntGQDfzFS7nAZgh5lt8bCdEnXnn++C/Fvfyj2+Zo0L8m9/u+RDaMw4VxKuA0iwyumhzwRwGYAzSa7O3M4heSXJKzPnPAvgfwCsB/AggKv8aa5ETnZ8/Jlnco/v3u1S+eSTy34oP8eM49jzT8J1AAmW1nKR6hTb+aeGnye/1jXJ3/AZcD1dhaPEkdZyEe/4WLHi15ix1z1/r3v7cfzrQaJJge6BVPxCBlB66NeYsZfVIl6P8+u6gXiq2Lq6ft+Ssh560tcxL7hYN+Db01W7nvxgvFxz3Ov1y7UeulQKWg/dP4lcx/zgQWDYsML3hfTzUgsvx9C9HufXeuhSKY2h+yhRkz82b3ZJkh/mzc2x3eIN8LZaxOtxftWai5cU6DVKxC/kCy+4pGtszD1+880uxH/3u3Da5SGvZo16Pc6vWnPxkgK9RrH+hbzrLhfkZ52Ve/yVV1yQ33ZbOO0KSTkXt72uDVetuXhJY+geqHivzLDNng28/PLA4x99BHzuc4E3JwpUqy5xMdgYugI9TYpNBurtLX5fSiTy4rYkki6Kpl2pGvIIh3lQNf6JurgtqaVAT7IQ1iH3UpCTbhJxcVtST4GeRDEP8qwgN3iI9cVtkQwFelJkh05iHOT5wyuFxrQBf4ZBVG0iSaBAj7udO10CDcn7rzz11NgEOVB4eKXY0H6twyDFxuXjvsORiAI9rt55xyXeqFG5xxctcon4xhvhtKtKhYZXCl2vrXUYRIthSZIp0OPm0UddyuVvHPHSSy6hbrwxlGbVqtgwipm3wyDaeFmSrMgKTBI5f/M3wD33DDz+4YfAuHGBN8drxxwTTB24yhMlydRDj7ovfMF1T/PD/MAB131NQJgDwVWZqDxRkkyBHlXZipUNG3KPZy90Dh0aTrt8ElSVicoTJcliFejaGSgeFSvVCqLKROWJkmSxCfTEVyf4FOSpeBOskMoTJaliE+iJrU7wsUee+DdBEclRMtBJPkJyK8mOIvfPJrmD5OrM7Wbvm5mw6oQDBwoH+cKFng6tJPZNUEQKKqds8acA7gXw2CDnvGpm53nSoiKKlbXFqjrho4+AMWMGHn/8ceDCCz1/ukS9CYpISSV76Gb2CoCPAmjLoGJdndDR4Xrj+WG+Zo3rjfsQ5oBK9ETSxqsx9K+QXEPyOZInFTuJ5AKS7STbu7u7K3qCWFYnPPmka+yXv5x7vLvbBXn+bE+PxfpNUEQqVtaORSSbASw3s0kF7hsFoNfMdpE8B8APzey4Uo+Z6B2LbrkFuP32gcf37weGBTs5N3bb44nIoAbbsajmdDGzT/p9/CzJ+0iONbNttT527Jx1FvDCCwOPh1g/3tqqABdJi5qHXEj+AenKNUjOyDxmT62PGyuzZrmhlfwwT8FkoFqpTl7EOyV76CR/BmA2gLEkuwDcAqAOAMzsfgAXAfg2yQMAPgVwqYW183TQii3YnZJvv1bZOvlsaWW2Th7QXxUi1SinyuVPzWy8mdWZWaOZPWxm92fCHGZ2r5mdZGaTzew0M3vd/2bXrqaeYaEa8vnz1SOvkOrkRbyVyuVzq+oZmg3cFQgAfvAD4Npr/Whm4qlOXsRbsZn676WKeoafflp4i7dnn3UhrzCvmurkRbyVykAvq2f4v//rgjy/kLujwwX52Wf71r60UJ28iLdSGeiD9gzb212QH3107p3ZyUAnFZ03JRWK5WQxkQhLZaAX6hn+2WGPo/MDAtOn596xb58L8rFjg2tgimgpWxHvpDLQ+/cMb8FtMBBtn12ce1Jvrwvyww4Lp5Epp/p0kcqlMtABoHXzP6PzA+JW3Jp7R7b0sFiNeUJFKUC1jrtIddIX6Fdc4cL6H/6h79jYsamuIY9agKo+XaQ66Qn0GTNckD/ySN+xO+5wCVbhyo9JE7UAVX26SHWSPbHIDKirAw4ezD2+bBlw0UXhtCmCohagidjMRCQEyeyh9/YCV17pBoT7h/nrr7uQV5jniNoEH9Wni1QnWYG+bx8wbx4wdCjwwAN9xzdscEH+la+E17YIi1qAqj5dpDrJGHL55BPgzDOBVav6js2ZAzz9NDB8eHjtiolsUEZpIwyt4y5SuXgH+ocfAlOnAlu29B2bPx946KHAdwaKOwWoSPzFc8jlv//b/S0+fnxfmN9wgxs7/+lPFeYikkrxS77164Hjj+/7/Ec/Ar7znfDaIyISEfEL9N//feDCC4E/+RN3ExERAHEM9FGjgMcfD7sVIiKRE88xdBERGUCBLiKSEAp0EZGEUKCLiCREyUAn+QjJrSQ7itxPkotJrif5Nsmp3jdTRERKKaeH/lMAcwe5/2wAx2VuCwD8uPZmiYhIpUoGupm9AuCjQU45H8Bj5rwBYDTJ8V41UEREyuPFGPrRADb1+7wrc2wAkgtItpNs7075phIiIl4L9KKomS0xsxYza2loaAjyqUVEEs+LQN8MYEK/zxszx6QCUdqkWUTiyYtAfwbANzPVLqcB2GFmW0p9kfSJ2ibNIhJP5ZQt/gzAfwH4IskukleQvJLklZlTngXwPwDWA3gQwFW+tTahorZJs4jEU8nFuczsT0vcbwCu9qxFKRS1TZpFJJ40UzQCorZJs4jEkwI9AqK2SXO5dCFXJFoU6BEQx13udSFXJHoSG+hx6z22tgKdnW5b1M7OaIc5oAu5IlEUvx2LypDtPWYDJ9t7BKIflHGhC7ki0ZPIHrp6j/7ThVyR6ElkoKv36L+4XsgVSbJEBrp6j/6L44VckaRLZKCr9xiMuF3IFUm6RAa6eo8ikkaJrHIBXHgrwEUkTRLZQxcRSSMFuohIQijQRUQSQoEuIpIQCnQRkYSg258ihCcmuwF8EMqTh2ssgG1hNyJkeg0cvQ6OXgen3NehycwaCt0RWqCnFcl2M2sJux1h0mvg6HVw9Do4XrwOGnIREUkIBbqISEIo0IO3JOwGRIBeA0evg6PXwan5ddAYuohIQqiHLiKSEAp0EZGEUKAHgOQjJLeS7Ai7LWEiOYHkCpJrSb5L8pqw2xQGkvUk3yS5JvM63BZ2m8JCcijJ35JcHnZbwkKyk+Q7JFeTbK/psTSG7j+SZwDYBeAxM5sUdnvCQnI8gPFm9hbJkQBWAfi6ma0NuWmBIkkAR5jZLpJ1AF4DcI2ZvRFy0wJH8m8BtAAYZWbnhd2eMJDsBNBiZjVPrlIPPQBm9gqAj8JuR9jMbIuZvZX5eCeAdQCODrdVwTNnV+bTuswtdT0rko0AzgXwUNhtSQoFuoSCZDOAUwCsDLkpocgMNawGsBXA82aWxtfhHgB/D6A35HaEzQD8muQqkgtqeSAFugSO5JEAfg7gWjP7JOz2hMHMDprZFACNAGaQTNVQHMnzAGw1s1VhtyUCTjezqQDOBnB1Zoi2Kgp0CVRmzPjnANrM7Imw2xM2M9sOYAWAuSE3JWgzAczLjB//K4AzSS4Nt0nhMLPNmX+3AngSwIxqH0uBLoHJXAx8GMA6M7s77PaEhWQDydGZj4cDmAPgvVAbFTAzu8HMGs2sGcClAF40s2+E3KzAkTwiUyAAkkcA+CqAqqvhFOgBIPkzAP8F4Isku0heEXabQjITwGVwvbHVmds5YTcqBOMBrCD5NoDfwI2hp7ZsL+XGAXiN5BoAbwL4pZn9qtoHU9miiEhCqIcuIpIQCnQRkYRQoIuIJIQCXUQkIRToIiIJoUAXEUkIBbqISEL8f6I99qiXGNOGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_plotter(data, true_w0=true_w0, true_w1=true_w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specification of the Pyro model and guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we specify a (Bayesian) linear regression model in Pyro. The 'data' argument is a dictionary covering the data of the predictor and response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_reg_model(data):\n",
    "\n",
    "    w0 = pyro.sample(\"w0\", dist.Normal(0.0, 0.01))\n",
    "    w1 = pyro.sample(\"w1\", dist.Normal(0.0, 0.01))\n",
    "\n",
    "    with pyro.plate(\"data_plate\"):\n",
    "        pyro.sample(\"y\", dist.Normal(data[\"x\"] * w1 + w0, 1.0), obs=data[\"y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we specify the variational distribution, which is called a guide in Pyro. We make the mean field assumption and assume that the variational distribution factorizes wrt. to 'w0' and 'w1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_reg_guide(data):\n",
    "    w0_mean = pyro.param(\"w0_mean\", torch.tensor(0.0))\n",
    "    w0_scale = pyro.param(\"w0_scale\", torch.tensor(1), constraint=constraints.positive)\n",
    "    pyro.sample(\"w0\", dist.Normal(w0_mean, w0_scale))\n",
    "    \n",
    "    w1_mean = pyro.param(\"w1_mean\", torch.tensor(0.0))\n",
    "    w1_scale = pyro.param(\"w1_scale\", torch.tensor(1), constraint=constraints.positive)\n",
    "    pyro.sample(\"w1\", dist.Normal(w1_mean, w1_scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning\n",
    "\n",
    "In this function the actual learning is taking place. Notice that the structure is similar to what we saw in the example notebooks during the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(N=10, data=None, lr=0.0001):\n",
    "    if data is None:\n",
    "        data = generate_data(N=N)\n",
    "\n",
    "    pyro.clear_param_store()\n",
    "\n",
    "    elbo = pyro.infer.Trace_ELBO()\n",
    "    svi = pyro.infer.SVI(model=lin_reg_model,\n",
    "                         guide=lin_reg_guide,\n",
    "                         optim=SGD({\"lr\": lr}),\n",
    "                         loss=elbo)\n",
    "\n",
    "    num_steps = 5000\n",
    "    for step in range(num_steps):\n",
    "        loss = svi.step(data)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            w0_mean = pyro.param(\"w0_mean\").detach().item()\n",
    "            w0_scale = pyro.param(\"w0_scale\").detach().item()\n",
    "            w1_mean = pyro.param(\"w1_mean\").detach().item()\n",
    "            w1_scale = pyro.param(\"w1_scale\").detach().item()\n",
    "            print(f\"Loss (iter: {step}): {loss}\")\n",
    "            print(f\"w0: {w0_mean} +/- {w0_scale}\\t \\t w1: {w1_mean} +/- {w1_scale}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss (iter: 0): 1474.1625847816467\n",
      "w0: -0.4862527847290039 +/- 0.7854659557342529\t \t w1: 0.1509019434452057 +/- 0.9820894598960876\n",
      "Loss (iter: 100): 264.1699321269989\n",
      "w0: 0.05245658755302429 +/- 0.07223188877105713\t \t w1: 0.013736292719841003 +/- 0.06580106914043427\n",
      "Loss (iter: 200): 195.60851192474365\n",
      "w0: 0.06265882402658463 +/- 0.04895464703440666\t \t w1: 0.04808889329433441 +/- 0.04835394397377968\n",
      "Loss (iter: 300): 211.56047582626343\n",
      "w0: 0.05243692919611931 +/- 0.04032494127750397\t \t w1: -0.04748903959989548 +/- 0.03968854621052742\n",
      "Loss (iter: 400): 213.45718920230865\n",
      "w0: -0.03036290407180786 +/- 0.03621416911482811\t \t w1: 0.05541557818651199 +/- 0.03504464775323868\n",
      "Loss (iter: 500): 187.5462040901184\n",
      "w0: 0.018604464828968048 +/- 0.03218503296375275\t \t w1: 0.024274293333292007 +/- 0.03041078895330429\n",
      "Loss (iter: 600): 192.97052681446075\n",
      "w0: 0.01795538142323494 +/- 0.03005146235227585\t \t w1: -0.026205625385046005 +/- 0.02786782570183277\n",
      "Loss (iter: 700): 229.02451825141907\n",
      "w0: -0.019035598263144493 +/- 0.028056712821125984\t \t w1: -0.043423138558864594 +/- 0.025892091915011406\n",
      "Loss (iter: 800): 192.26730489730835\n",
      "w0: 0.003826545551419258 +/- 0.02643257938325405\t \t w1: 0.035018134862184525 +/- 0.024141691625118256\n",
      "Loss (iter: 900): 203.9411517381668\n",
      "w0: 0.04525695741176605 +/- 0.024377955123782158\t \t w1: 0.05678774416446686 +/- 0.023316487669944763\n",
      "Loss (iter: 1000): 189.7669676542282\n",
      "w0: -0.016124555841088295 +/- 0.023253783583641052\t \t w1: 0.04017658159136772 +/- 0.022339869290590286\n",
      "Loss (iter: 1100): 187.55570077896118\n",
      "w0: 0.0054205674678087234 +/- 0.021994173526763916\t \t w1: 0.02280164323747158 +/- 0.021346019580960274\n",
      "Loss (iter: 1200): 206.72594702243805\n",
      "w0: 0.042603831738233566 +/- 0.021226953715085983\t \t w1: 0.027065381407737732 +/- 0.02053653448820114\n",
      "Loss (iter: 1300): 191.66733920574188\n",
      "w0: 0.01586868241429329 +/- 0.02065240405499935\t \t w1: 0.01894865743815899 +/- 0.02001890540122986\n",
      "Loss (iter: 1400): 202.12356460094452\n",
      "w0: 0.03988438844680786 +/- 0.019989049062132835\t \t w1: 0.03949669003486633 +/- 0.019515829160809517\n",
      "Loss (iter: 1500): 190.1310180425644\n",
      "w0: 0.03229943662881851 +/- 0.01954924687743187\t \t w1: 0.04064261540770531 +/- 0.019151879474520683\n",
      "Loss (iter: 1600): 189.17752063274384\n",
      "w0: -0.01504058949649334 +/- 0.018859874457120895\t \t w1: 0.07371559739112854 +/- 0.018505634739995003\n",
      "Loss (iter: 1700): 187.73917770385742\n",
      "w0: -0.007159021217375994 +/- 0.018505902960896492\t \t w1: 0.028785016387701035 +/- 0.018127581104636192\n",
      "Loss (iter: 1800): 199.5281171798706\n",
      "w0: 0.025281401351094246 +/- 0.018118273466825485\t \t w1: 0.05302193760871887 +/- 0.01757742092013359\n",
      "Loss (iter: 1900): 197.64163398742676\n",
      "w0: 0.024295007809996605 +/- 0.017699772492051125\t \t w1: 0.040453482419252396 +/- 0.017290985211730003\n",
      "Loss (iter: 2000): 194.15776538848877\n",
      "w0: 0.02606295421719551 +/- 0.01729336939752102\t \t w1: 0.05044824630022049 +/- 0.016979800537228584\n",
      "Loss (iter: 2100): 194.21790647506714\n",
      "w0: 0.008585801348090172 +/- 0.016965258866548538\t \t w1: 0.03501644730567932 +/- 0.016627134755253792\n",
      "Loss (iter: 2200): 188.59594678878784\n",
      "w0: 0.018640533089637756 +/- 0.016558442264795303\t \t w1: 0.051881514489650726 +/- 0.016391990706324577\n",
      "Loss (iter: 2300): 194.1716184616089\n",
      "w0: 0.003131542354822159 +/- 0.016274116933345795\t \t w1: 0.010634109377861023 +/- 0.016034137457609177\n",
      "Loss (iter: 2400): 189.41357278823853\n",
      "w0: 0.019115623086690903 +/- 0.016057230532169342\t \t w1: 0.03220272436738014 +/- 0.01575336791574955\n",
      "Loss (iter: 2500): 198.2998298406601\n",
      "w0: 0.0014045275747776031 +/- 0.01590847223997116\t \t w1: 0.05644351243972778 +/- 0.015466847456991673\n",
      "Loss (iter: 2600): 187.33998727798462\n",
      "w0: 0.0374736413359642 +/- 0.015755705535411835\t \t w1: 0.023436447605490685 +/- 0.015260245651006699\n",
      "Loss (iter: 2700): 188.71545112133026\n",
      "w0: 0.02990797534584999 +/- 0.015486810356378555\t \t w1: 0.048498716205358505 +/- 0.015037288889288902\n",
      "Loss (iter: 2800): 187.98796224594116\n",
      "w0: 0.029316429048776627 +/- 0.015276276506483555\t \t w1: 0.02303113415837288 +/- 0.014902726747095585\n",
      "Loss (iter: 2900): 187.53288638591766\n",
      "w0: -0.0008382108062505722 +/- 0.015060538426041603\t \t w1: 0.03172817826271057 +/- 0.014605404809117317\n",
      "Loss (iter: 3000): 191.02009534835815\n",
      "w0: 0.022168874740600586 +/- 0.01490745972841978\t \t w1: 0.025059271603822708 +/- 0.014320540241897106\n",
      "Loss (iter: 3100): 194.45757472515106\n",
      "w0: -0.002875138074159622 +/- 0.014704465866088867\t \t w1: 0.0344657227396965 +/- 0.014215630479156971\n",
      "Loss (iter: 3200): 187.94571554660797\n",
      "w0: 0.013805648311972618 +/- 0.014428578317165375\t \t w1: 0.036177054047584534 +/- 0.014045766554772854\n",
      "Loss (iter: 3300): 195.4285397529602\n",
      "w0: 0.015606950037181377 +/- 0.014240081422030926\t \t w1: 0.03738994896411896 +/- 0.013897732831537724\n",
      "Loss (iter: 3400): 188.21292281150818\n",
      "w0: 0.011080972850322723 +/- 0.014030584134161472\t \t w1: 0.019301101565361023 +/- 0.013744303025305271\n",
      "Loss (iter: 3500): 188.69082689285278\n",
      "w0: 0.01764589548110962 +/- 0.013916744850575924\t \t w1: 0.039065662771463394 +/- 0.0136003028601408\n",
      "Loss (iter: 3600): 191.55665063858032\n",
      "w0: 0.004299750551581383 +/- 0.013840177096426487\t \t w1: 0.030415905639529228 +/- 0.013544212095439434\n",
      "Loss (iter: 3700): 188.49102365970612\n",
      "w0: -0.008585074916481972 +/- 0.013776356354355812\t \t w1: 0.037603944540023804 +/- 0.01345575787127018\n",
      "Loss (iter: 3800): 188.1086621284485\n",
      "w0: -0.0035438667982816696 +/- 0.01368289440870285\t \t w1: 0.025857239961624146 +/- 0.013345086947083473\n",
      "Loss (iter: 3900): 188.71142506599426\n",
      "w0: -0.0021082041785120964 +/- 0.013567042537033558\t \t w1: 0.03660723194479942 +/- 0.013176794163882732\n",
      "Loss (iter: 4000): 191.0858793258667\n",
      "w0: 0.010741399601101875 +/- 0.013463465496897697\t \t w1: 0.035888709127902985 +/- 0.013031777925789356\n",
      "Loss (iter: 4100): 191.60703337192535\n",
      "w0: 0.01500720251351595 +/- 0.0133272809907794\t \t w1: 0.044425949454307556 +/- 0.012953301891684532\n",
      "Loss (iter: 4200): 187.63937556743622\n",
      "w0: 0.022873861715197563 +/- 0.013197463005781174\t \t w1: 0.04526583477854729 +/- 0.012903392314910889\n",
      "Loss (iter: 4300): 188.56778025627136\n",
      "w0: 0.005821262486279011 +/- 0.013130875304341316\t \t w1: 0.016514597460627556 +/- 0.012801182456314564\n",
      "Loss (iter: 4400): 190.25918102264404\n",
      "w0: 0.010792035609483719 +/- 0.013049319386482239\t \t w1: 0.028962789103388786 +/- 0.012754425406455994\n",
      "Loss (iter: 4500): 198.2728295326233\n",
      "w0: 0.008612689562141895 +/- 0.012914927676320076\t \t w1: 0.014033738523721695 +/- 0.012654186226427555\n",
      "Loss (iter: 4600): 191.9291706085205\n",
      "w0: 0.005064178258180618 +/- 0.012856930494308472\t \t w1: 0.01812855154275894 +/- 0.012559297494590282\n",
      "Loss (iter: 4700): 191.34014642238617\n",
      "w0: -0.0003679431974887848 +/- 0.012763794511556625\t \t w1: 0.03318879380822182 +/- 0.012438098900020123\n",
      "Loss (iter: 4800): 190.03185558319092\n",
      "w0: 0.008678540587425232 +/- 0.012685880064964294\t \t w1: 0.021213077008724213 +/- 0.012399211525917053\n",
      "Loss (iter: 4900): 188.13240087032318\n",
      "w0: 0.0013177033979445696 +/- 0.01256199274212122\t \t w1: 0.024316176772117615 +/- 0.012388644739985466\n"
     ]
    }
   ],
   "source": [
    "learn(data=data, lr=0.0001) # default lr \n",
    "# learn(data=data, lr=.01) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the results\n",
    "\n",
    "Here we sample weights from the posterior distributions over 'w0' and 'w1'. The distribution of the generated weights (and the corresponding models) illustrates how confident we are in the model, an insight you cannot get when only having point estimates of the model parameters as found with, e.g., maximum likelihood learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "    w0_mean = pyro.param(\"w0_mean\").detach().item()\n",
    "    w0_scale = pyro.param(\"w0_scale\").detach().item()\n",
    "    w1_mean = pyro.param(\"w1_mean\").detach().item()\n",
    "    w1_scale = pyro.param(\"w1_scale\").detach().item()\n",
    "    w0_sample = pyro.sample(\"w0_sample\", dist.Normal(w0_mean, w0_scale)).numpy()\n",
    "    w1_sample = pyro.sample(\"w1_sample\", dist.Normal(w1_mean, w1_scale)).numpy()\n",
    "    data_plotter(data, approx_w0=w0_sample, approx_w1=w1_sample, legend=False)\n",
    "data_plotter(data, legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises:\n",
    "        * Generate data sets of varying sizes and characteristics (by changing the parameters in the 'generate_data' function) and investigate and compare the resulting models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__default__:\n",
    "- True model: y = 1 + 0.5 * x, samples = 50 (DEFAULT)\n",
    "- Sensor precision: 1/sqrt(4) (DEFAULT)\n",
    "- Learned model: w0 = N(1.1,0.18) | w1 = N(0.46, 0.065)\n",
    "\n",
    "__sample=10__:\n",
    "- True model: y = 1 + 0.5 * x, samples = 10 (will try lowering the number of samples expect more variance)\n",
    "- Sensor precision: 1/sqrt(4) (DEFAULT)\n",
    "- Learned model: w0 = N(0.64,0.38) | w1 = N(0.7, 0.13)\n",
    "- Conclusion: more variance + more away from true model\n",
    "\n",
    "__Sensor precision=1/sqrt(1)__:\n",
    "- True model: y = 1 + 0.5 * x, samples = 50 (DEFAULT)\n",
    "- Sensor precision: 1/sqrt(1) (decreasing sensor precision, expect more variance)\n",
    "- Learned model: w0 = N(1.25,.18) | w1 = N(0.44, 0.064)\n",
    "- Conclusion: more variance + more away from true model + in the plot, majority of dots were ouside the approx drawn lines\n",
    "\n",
    "__Sensor precision=1/sqrt(8)__:\n",
    "- True model: y = 1 + 0.5 * x, samples = 50 (DEFAULT)\n",
    "- Sensor precision: 1/sqrt(8) (doubling sensor precision, expect less variance)\n",
    "- Learned model: w0 = N(1.09,0.17) | w1 = N(0.49, 0.063)\n",
    "- Conclusion: more or less similar to default, so doubling sensor quality does not give double performance\n",
    "\n",
    "__Samples = 1000__:\n",
    "- True model: y = 1 + 0.5 * x, samples = 1000 (increase samples a lot, expect less variance)\n",
    "- Sensor precision: 1/sqrt(4) (DEFAULT)\n",
    "- Learned model: w0 = N(1.02,0.04) | w1 = N(0.494, 0.014)\n",
    "- Conclusion: best model yet (samples = 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * Analyze how learning is affected by changing the learning rate and the initial values of the parameters specified in the guide function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using default data setup: \n",
    "- True model: y = 1 + 0.5 * x, samples = 50 (DEFAULT)\n",
    "- Sensor precision: 1/sqrt(4) (DEFAULT)\n",
    "- lr = 0.0001 (DEFAULT)\n",
    "- w0_mu = 0, w0_sigma = 1 (DEFAULT)\n",
    "- w1_mu = 0, w1_sigma = 1 (DEFAULT)\n",
    "- learned model: w0 = N(1.1,0.18) | w1 = N(0.46, 0.065)\n",
    "\n",
    "__lr = 0.001__:\n",
    "- lr = 0.001 (increasing lr)\n",
    "- w0_mu = 0, w0_sigma = 1 (DEFAULT)\n",
    "- w1_mu = 0, w1_sigma = 1 (DEFAULT)\n",
    "- learned model: w0 = N(1.15,0.14) | w1 = N(0.47, 0.049)\n",
    "- Conclusion: similar to default, \n",
    "\n",
    "__lr = 0.01__:\n",
    "- lr = 0.01 (increasing lr)\n",
    "- w0_mu = 0, w0_sigma = 1 (DEFAULT)\n",
    "- w1_mu = 0, w1_sigma = 1 (DEFAULT)\n",
    "- Crashes in leaning here: \" Expected parameter scale (Tensor of shape ()) of distribution Normal(loc: 13.8917818069458, scale: 0.0) to satisfy the constraint GreaterThan(lower_bound=0.0), but found invalid values:\n",
    "0.0\"\n",
    "\n",
    "__moving priors far away from true model__:\n",
    "- w0_mu = -10, w0_sigma = 1 \n",
    "- w1_mu = 10, w1_sigma = 1 \n",
    "- lr = 0.0001 (DEFAULT)\n",
    "- learned model: w0 = N(0.89, 0.18) | w1 = N(0.55, 0.065)\n",
    "- Conclusion: a bit off from true model, but still pretty close\n",
    "\n",
    "__increasing confidence in wrong guide params__:\n",
    "- w0_mu = -10, w0_sigma = 0.001 \n",
    "- w1_mu = 10, w1_sigma = 0.001 \n",
    "- lr = 0.0001 (DEFAULT)\n",
    "- learned model: w0 = N(.89, 0.001) | w1 = N(.55, 0.001)\n",
    "- conclusion: a bit off from true model, but still pretty close, low variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        * Experiment with different types of prior knowledge in the model specification (e.g. change the mean and scale of the distributions over the weights). For instance, we may (mostly likely erroneously considering the data) have a prior expectation that 'w0' is around 5.0, and we can encode the strength of this belief through the scale of the corresponding distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using default data setup: \n",
    "- True model: y = 1 + 0.5 * x, samples = 50 (DEFAULT)\n",
    "- Sensor precision: 1/sqrt(4) (DEFAULT)\n",
    "- lr = 0.0001 (DEFAULT)\n",
    "- w0_mu = 0, w0_sigma = 1 (DEFAULT)\n",
    "- w1_mu = 0, w1_sigma = 1 (DEFAULT)\n",
    "- prior model: \n",
    "    - w0 = pyro.sample(\"w0\", dist.Normal(0.0, 1000.0))\n",
    "    - w1 = pyro.sample(\"w1\", dist.Normal(0.0, 1000.0))\n",
    "\n",
    "__moving locs far away from true model__:\n",
    "- w0 = pyro.sample(\"w0\", dist.Normal(-100.0, 1000.0))\n",
    "- w1 = pyro.sample(\"w1\", dist.Normal(100.0, 1000.0))\n",
    "- learned model: w0 = N(1.14, 0.18) | w1 = N(0.55, 0.065) \n",
    "- conclusion: little impact from default\n",
    "\n",
    "__increasing confidence in prior__:\n",
    "- w0 = pyro.sample(\"w0\", dist.Normal(0.0, 0.01))\n",
    "- w1 = pyro.sample(\"w1\", dist.Normal(0.0, 0.01))\n",
    "- learned model: w0 = N(-0.0007222937420010567,0.012490347027778625), w1 = N(0.052780792117118835,0.012352855876088142)\n",
    "- conclusion: increadibly wrong, increasing confidence in wrong prior is most detrimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
