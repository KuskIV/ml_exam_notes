---
title: 09 - Probabilistic Graphical Models
created: '2022-06-02T07:49:26.203Z'
modified: '2022-06-02T07:50:02.823Z'
---

# 09 - Probabilistic Graphical Models

In probabilistic graphical models, the focus on the Hiddden Markov Model, which enables modeling temporal sequences of events, in terms of the probabilities of certain events happening in certain states.

## Specification of a HMM Model

Formally we characterize a HMM as a 5-tuple of the form $(S, V, A, B, \pi)$ where:

> - $S = \{s_1, ..., s_N\}$ is the set of **states**
> - $V = \{v_1, ..., v_M\}$ is the set of possible **observations** in the states (sensor measurements in TD lingo)
> - $A$ is the **transition matrix**, which is a NxN matrix, where N is the number of states, and  $a_{ij} = P(q_{t+1} = S_i | q_t = S_j)$ is the probability of transitioning from state i at the time t to state j at the time t+1, if one can not transtion from one state to another of course then $a_{ij} = 0$
> - $B$ is the **observation symbol probability distribution** in state j, it is given by $B = \{b_j(k)\}$, where $b_j(k) = P(V_k at t | q_t = S_j)$ that is it denotes the probabilitiy of observing the symmbol $V_k$ at time $t$ in state $S_j$
> - $\pi$ is the **initial state distribution**, it is given by $\pi = \{\pi\}$, where $\pi_i = P(q_1 = S_i)$ that is it denotes the probabilitiy of starting in state $S_i$

Now what can we use such a HMM to? 

Now given an appropriate 5-tuple $(S, V, A, B, \pi)$  we can use the model as a generator to give an observation sequence $O = O_1, O_2, \ldots, O_T$, where each obseration $O_t$ is a member of the set $V$ and $T$ is the length of the sequence, the process is as follows:

1. We sample a state $q_1 = S_i$ from the initial state distribution $\pi$
2. We sample an observation $O_1 = V_k$ from the observation symbol probability distribution $B$ at state $q_1$
3. We sample a state $q_2 = S_j$ from the transition matrix $A$ at state $q_1$
4. Now we can go back to step one to sample $O_{t+1}$ if $t + 1 \leq T$, otherwise we are done.

The above procedure describes how to use a HMM as a generator of observations. 
Now the HMM is denoted by a 5 tuple but the parameters of the model are the 3-tuple $A,B,\pi$ that is the state transition matrix, the observation symbol probability distribution and the initial state distribution. For convenience denote the model parameters by $\lambda = (A, B, \pi)$

# The 3 Key Basic Problems To Solve With HMMs

Now we can use the HMM to solve the following 3 key basic problems:

- <em>Problem 1:</em> Given a sequence of observations $O = O_1, O_2, \ldots, O_T$ and a HMM model specified by $\lambda = (A,B,\pi)$, how do we effeciently compute $P(O|\lambda)$, that is compute the probability that this sequence was actually generated by the model $\lambda$?
- <em>Problem 2:</em> Given a sequence of observations $O = O_1, O_2, \ldots, O_T$ and a HMM model specified by $\lambda = (A,B,\pi)$, how do we choose a corresponding state sequence $Q = q_1, q_2, \ldots, q_T$ that best explains the observation (most likely sequence of states)?
- <em>Problem 3:</em> How do we adjust the model parameters $\lambda = (A,B,\pi)$ to maximize $P(O|\lambda)$? (that is increase the likelihood of the model parameters $\lambda$)

### Solution to Problem 1
Here we aim to solve the problem of computing the probability of a sequence of observations given a model. That is given $O = O_1, O_2, \ldots, O_T$ and a HMM model specified by $\lambda = (A,B,\pi)$, how do we compute $P(O|\lambda)$.

One naive solution would be to enumerate all possible state transition $Q = q_1, q_2, \ldots, q_T$ and compute the probability of each state sequence $Q$ given the observation sequence $O$. This is a brute force approach and is computationally expensive as there will be $N^T$ such sequences that is $N$ denotes the number of states and $T$ the sequence length, hence assumming all possible such sequences with replacment, and $N^T$ is without even considering cost of computing the probability of $P(O|Q,\lambda) that is considering one such specific state sequence.

However considering the computations will make the following better solution clearer, so we proceed showing the naive apporach:
Now assume we have a fixed state sequence $Q = q_1, q_2, \ldots, q_T$, (we assume independence of the observations), so:

- $P(O|Q,\lambda) = \prod_{t=1}^T P(O_t|q_t,\lambda)$

So the probability of observing $O$ given $Q$ and $\lambda$ is just the product of observing each observation $O_t$ given the state $q_t$ and the model parameters $\lambda$. For this we would use $A$ the state transition matrix, and $B$ the observation symbol probability distribution and $pi$ the initial state distribution. Let's unpack this:

The probability for observing the observation sequence given the sate sequence and the model is:
- $P(O|Q,\lambda) = b_{q_1}(O_1)b_{q_2}(O_2)\ldots b_{q_T}(O_T)$

The probability of the state sequence is:

- $P(Q|\lambda) = \prod_{t=1}^T P(q_t|q_{t-1},\lambda) = \pi_{q_1}a_{q_1,q_2}a_{q_2,q_3}\ldots a_{q_{T-1},q_{T}}$

Now how to compute the joint probability of both observing $O$ and having the state sequence $Q$? We can compute the joint probability of $O$ and $Q$ as:

- $P(O,Q) = P(O|Q,\lambda)P(Q|\lambda)$

Now this was for one specific state sequence $Q$, to generalize we get:
$P(O|\lambda) = \sum_{\text{all} \ Q} P(O|Q,\lambda) = \sum_{q_1,q_2,\ldots,q_T} \pi_1b_{q_1}(O_1)a_{q_1,q_2}b_{q_2}(O_2)\ldots a_{q_{T-1},q_T}b_{q_T}(O_T)$

So now we see the full computations is $\mathcal{O}(2T \cdot N^T)$

Now having considered the naive approach the effecient approach makes use of the **Forward-Backward procedure**, which makes use of dynamic programming. 

First focus on the Forward part:

Let $\alpha_t(i) = P(O_1, O_2, \ldots,O_t, q_t=S_i | \lambda)$ That is the probability of the partial observation sequence $O_1, O_2, \ldots, O_t$ (until time t) and the state $q_t = S_i$ given model parameters $\lambda$. That is observing all these observations and landing with state $q_t = S_i$.
We can solve now inductively with for $\alpha_t$:

1. Initialization: $\alpha_1(i) = \pi_ib_i(O_1) \quad\quad\quad\quad  1 \leq i \leq N$  
2. Induction: $\alpha_{t+1}(j) = \left[ \sum_{i=1}^N \alpha_t(i)a_{i,j}b_j(O_{t+1}) \right] \quad\quad\quad\quad 1 \leq t \leq T - 1, 1 \leq j \leq N$
3. Termination
$P(O|\lambda) = \sum_{i=1}^N \alpha_T(i)$

As a matter of fact the forward procedure alone as we can see suffices to solve problem 1, however the backward procedure will be important for the following problems, so it is good to have a look at it. Now let's try and explain the three steps above of the forward procedure.
In essence the forward procedure makes use of dynamic programming to solve subproblems, store them and reuse them in the larger problems which is composed of the subproblems. Image a grid with T rows and N colums, so in the first column (T=1) we have N option for what could have been the first state, similarly for column (2) so we move from left to right, and then when solving for example column 3 (T=3), we can make use of solutions for T-1.
1. Here just initialized 
