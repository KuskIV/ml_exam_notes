---
title: 09 - Probabilistic Graphical Models
created: '2022-06-02T07:49:26.203Z'
modified: '2022-06-02T07:50:02.823Z'
---

# 09 - Probabilistic Graphical Models

In probabilistic graphical models, the focus on the Hiddden Markov Model, which enables modeling temporal sequences of events, in terms of the probabilities of certain events happening in certain states.

## Specification of a HMM Model

Formally we characterize a HMM as a 5-tuple of the form $(S, V, A, B, \pi)$ where:

> - $S = \{s_1, ..., s_N\}$ is the set of **states**
> - $V = \{v_1, ..., v_M\}$ is the set of possible **observations** in the states (sensor measurements in TD lingo)
> - $A$ is the **transition matrix**, which is a NxN matrix, where N is the number of states, and  $a_{ij} = P(q_{t+1} = S_i | q_t = S_j)$ is the probability of transitioning from state i at the time t to state j at the time t+1, if one can not transtion from one state to another of course then $a_{ij} = 0$
> - $B$ is the **observation symbol probability distribution** in state j, it is given by $B = \{b_j(k)\}$, where $b_j(k) = P(V_k at t | q_t = S_j)$ that is it denotes the probabilitiy of observing the symmbol $V_k$ at time $t$ in state $S_j$
> - $\pi$ is the **initial state distribution**, it is given by $\pi = \{\pi\}$, where $\pi_i = P(q_1 = S_i)$ that is it denotes the probabilitiy of starting in state $S_i$

Now what can we use such a HMM to? 

Now given an appropriate 5-tuple $(S, V, A, B, \pi)$  we can use the model as a generator to give an observation sequence $O = O_1, O_2, \ldots, O_T$, where each obseration $O_t$ is a member of the set $V$ and $T$ is the length of the sequence, the process is as follows:

1. We sample a state $q_1 = S_i$ from the initial state distribution $\pi$
2. We sample an observation $O_1 = V_k$ from the observation symbol probability distribution $B$ at state $q_1$
3. We sample a state $q_2 = S_j$ from the transition matrix $A$ at state $q_1$
4. Now we can go back to step one to sample $O_{t+1}$ if $t + 1 \leq T$, otherwise we are done.

The above procedure describes how to use a HMM as a generator of observations. 
Now the HMM is denoted by a 5 tuple but the parameters of the model are the 3-tuple $A,B,\pi$ that is the state transition matrix, the observation symbol probability distribution and the initial state distribution. For convenience denote the model parameters by $\lambda = (A, B, \pi)$

# The 3 Key Basic Problems To Solve With HMMs

Now we can use the HMM to solve the following 3 key basic problems:

- <em>Problem 1:</em> Given a sequence of observations $O = O_1, O_2, \ldots, O_T$ and a HMM model specified by $\lambda = (A,B,\pi)$, how do we effeciently compute $P(O|\lambda)$, that is compute the probability that this sequence was actually generated by the model $\lambda$?
- <em>Problem 2:</em> Given a sequence of observations $O = O_1, O_2, \ldots, O_T$ and a HMM model specified by $\lambda = (A,B,\pi)$, how do we choose a corresponding state sequence $Q = q_1, q_2, \ldots, q_T$ that best explains the observation (most likely sequence of states)?
- <em>Problem 3:</em> How do we adjust the model parameters $\lambda = (A,B,\pi)$ to maximize $P(O|\lambda)$? (that is increase the likelihood of the model parameters $\lambda$)

### Solution to Problem 1
Here we aim to solve the problem of computing the probability of a sequence of observations given a model. That is given $O = O_1, O_2, \ldots, O_T$ and a HMM model specified by $\lambda = (A,B,\pi)$, how do we compute $P(O|\lambda)$.

One naive solution would be to enumerate all possible state transition $Q = q_1, q_2, \ldots, q_T$ and compute the probability of each state sequence $Q$ given the observation sequence $O$. This is a brute force approach and is computationally expensive as there will be $N^T$ such sequences that is $N$ denotes the number of states and $T$ the sequence length, hence assumming all possible such sequences with replacment, and $N^T$ is without even considering cost of computing the probability of $P(O|Q,\lambda) that is considering one such specific state sequence.

However considering the computations will make the following better solution clearer, so we proceed showing the naive apporach:
Now assume we have a fixed state sequence $Q = q_1, q_2, \ldots, q_T$, (we assume independence of the observations), so:

- $P(O|Q,\lambda) = \prod_{t=1}^T P(O_t|q_t,\lambda)$

So the probability of observing $O$ given $Q$ and $\lambda$ is just the product of observing each observation $O_t$ given the state $q_t$ and the model parameters $\lambda$. For this we would use $A$ the state transition matrix, and $B$ the observation symbol probability distribution and $pi$ the initial state distribution. Let's unpack this:

The probability for observing the observation sequence given the sate sequence and the model is:
- $P(O|Q,\lambda) = b_{q_1}(O_1)b_{q_2}(O_2)\ldots b_{q_T}(O_T)$

The probability of the state sequence is:

- $P(Q|\lambda) = \prod_{t=1}^T P(q_t|q_{t-1},\lambda) = \pi_{q_1}a_{q_1,q_2}a_{q_2,q_3}\ldots a_{q_{T-1},q_{T}}$

Now how to compute the joint probability of both observing $O$ and having the state sequence $Q$? We can compute the joint probability of $O$ and $Q$ as:

- $P(O,Q) = P(O|Q,\lambda)P(Q|\lambda)$

Now this was for one specific state sequence $Q$, to generalize we get:
$P(O|\lambda) = \sum_{\text{all} \ Q} P(O|Q,\lambda) = \sum_{q_1,q_2,\ldots,q_T} \pi_1b_{q_1}(O_1)a_{q_1,q_2}b_{q_2}(O_2)\ldots a_{q_{T-1},q_T}b_{q_T}(O_T)$

So now we see the full computations is $\mathcal{O}(2T \cdot N^T)$

Now having considered the naive approach the effecient approach makes use of the **Forward-Backward procedure**, which makes use of dynamic programming. 

First focus on the Forward part:

Let $\alpha_t(i) = P(O_1, O_2, \ldots,O_t, q_t=S_i | \lambda)$ That is the probability of the partial observation sequence $O_1, O_2, \ldots, O_t$ (until time t) and the state $q_t = S_i$ given model parameters $\lambda$. That is observing all these observations and landing with state $q_t = S_i$.
We can solve now inductively with for $\alpha_t$:

1. Initialization: $\alpha_1(i) = \pi_ib_i(O_1) \quad\quad\quad\quad  1 \leq i \leq N$  
2. Induction: $\alpha_{t+1}(j) = \left[ \sum_{i=1}^N \alpha_t(i)a_{i,j}\right]b_j(O_{t+1})  \quad\quad\quad\quad 1 \leq t \leq T - 1, 1 \leq j \leq N$
3. Termination
$P(O|\lambda) = \sum_{i=1}^N \alpha_T(i)$

As a matter of fact the forward procedure alone as we can see suffices to solve problem 1, however the backward procedure will be important for the following problems, so it is good to have a look at it. Now let's try and explain the three steps above of the forward procedure.
In essence the forward procedure makes use of dynamic programming to solve subproblems, store them and reuse them in the larger problems which is composed of the subproblems. Image a grid/lattice with T rows and N colums, so in the first column (T=1) we have N option for what could have been the first state, similarly for column (2) so we move from left to right, and then when solving for example column 3 (T=3), we can make use of solutions for T-1.
1. Here just initialized for each possible state what would be the probability of the first observation given the state.
2. we make the inductive step, where we use solutions for T-1, transition to the assumed state j in T, and compute what is the probability of $\alpha_{T+1}(j) from $q_{t-1} = i \quad \quad \quad 1 \leq i \leq N$
3. Termination each $\alpha_T(i)$ we will have N of these on for eact state, we sum then and we have computed as we wanted exactly the solution to problem 1, note that in practice we use log for numerical stability and avoid underflow. The forward procedure has complexity of $\mathcal{O}(T \cdot N^2)$

Now we have already solve Problem 1, but let's consider what is the backward procedure, as it will be useful in the following.
Let $\beta_t(i) = P(O_{t+1}, O_{t+2}, \ldots, O_T | q_t=S_i, \lambda)$ That is the probability of the partial observation sequence $O_{t+1}, O_{t+2}, \ldots, O_T$ (until time t) and the state $q_t = S_i$ given model parameters $\lambda$. That is observing (think backwards) all these observations and landing with state $q_t = S_i$. 
1. Initialization: $\beta_T(i) = 1 \quad\quad\quad\quad  1 \leq i \leq N$
2. Induction: $\beta_{t}(i) = \sum_{j=1}^N a_{i,j}b_j(O_{t+1}) \beta_{t+1}(j) \quad\quad\quad\quad 1 \leq t \leq T - 1, 1 \leq i \leq N$

Step 1 we just initalize to 1, and then in the inductive step 2, we compute by considering that we are in state $S_i$ at time $t$ ($\beta_t(i)$), and the way to be there is by having in one of the N states in step $t+1$ and having made the transition $a_ij$ and having the observation $b_j(O_{t+1})$ and lastly accounting for the remaining of the sequence $\beta_{t+1}(j)$

### Solution to Problem 2
That is given the observation sequence $O$ and the model parameters $\lambda$ how can we compute the most likely state sequence $Q$. To solve this we again use dynamic programming in what is called the Viterbi algorithm, to compute it. We proceed inductively by computing the most likely sequences of states q_0, and then consider q_0, q_1, and so on.
Define $\delta_t(i) = \text{max}_{q_1,q_2,\ldots,q_{t-1}} P(q_1,\ldots,q_t=i,O_1,\ldots,O_t|\lambda)$
that is $\delta_t(i)$ denotes the highest probability along a single path at time t, and ends in state s_i. Now considering the steps of the Viterbi algorithm:
1. Initialization: $\delta_1(i) = \pi_ib_i(O_1)$ for each state $i$
2. Recursion: $\delta_t(j) = \text{max}_{1 \leq i \leq N} \left( \delta_{t-1}(i)a_{ij}\right)b_j(O_t)$
3. Termination $p* = \text{max}_{1 \leq i \leq N} \delta_T(i)$

Along the computation we simply also just store the most likely state sequence $q_t$ at each time step, and then we can reconstruct the most likely state sequence by backtracking from the end. It is very similar to the forward procedure, now we just track which sequence is most likely.

### Solution to Problem 3
How do we adjust the model parameters $\lambda = (A,B,\pi)$ in order to maximize the probability of the observation sequence $P(O|\lambda)$? That is how do fit the model to the data.

There is no known way to solve the optimization problem analytically. However we can optimize it locally using the Expectation-Modification **EM** algoirthm or using gradient methods. We will consider **EM**, which makes use of the **forward-backward** procedure.

Define $\xi_t(i,j)$ as the probability of being in state $S_i$ at time $t$ and in state $S_j$ at time $t+1$, given the model $\lambda$ and the observation sequence $O$:
$\xi_t(i,j) = P(q_t=S_i, q_{t+1}=S_j|O,\lambda)$
The sequence of events leading up to $\xi_t(i,j)$ is $alpha_t(i)$ that is the forward sequence up to time $t$ ending in state $S_i$ and it is $beta_{t+1}(j)$ the backwards sequence to time $t+1$ ending in state $S_j$. Between these two we have the probability of the transition $a_{ij}$ and the probability of the observation $b_j(O_t)$. Using this expand on $\xi_t(i,j)$ to get the following:
$\xi_t(i,j) = \frac{P(q_t=S_i, q_{t+1}=S_j, O | \lambda)}{P(O|\lambda)}$

$ = \frac{\alpha_t(i)a_{ij}b_j(O_t) \beta_{t+1}(j)}{P(O | \lambda)}$

$ = \frac{\alpha_t(i)a_{ij}b_j(O_t) \beta_{t+1}(j)}{\sum_{i=1}^N\sum_{j=1}^N \alpha_t(i)a_{i,j}b_j(O_{t+1})\beta_{t+1}(j)}$

Similarly define now $\gamma_t(i)$ as the probability of being in state $S_i$ at time $t$ given the model $\lambda$ and the observation sequence $O$. 
$\gamma_t(i) = \frac{\alpha_t(i)\beta_t(i)}{P(O|\lambda)} = \frac{\alpha_t(i)\beta_t(i)}{\sum_{i=1}^N\alpha_t(i)\beta_t(i)}$

This can be computed also from our just defined $\xi_t(i,j)$, by:
$\gamma_t(i) = \sum_{j=1}^N \xi_t(i,j)$

Now 


